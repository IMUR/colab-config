{{/*
Node-Specific Configuration Template Example
This template demonstrates advanced patterns for node-specific configuration
using Chezmoi's template system with Co-lab cluster data variables.
*/}}

{{/* Header with node information */}}
#!/bin/bash
# Node-specific configuration for {{ .chezmoi.hostname }}
# Generated by Chezmoi on {{ now | date "2006-01-02 15:04:05" }}
# Node Role: {{ .node_role }}
# Architecture: {{ .chezmoi.arch }}

{{/* Basic node identification */}}
export CLUSTER_NODE="{{ .chezmoi.hostname }}"
export NODE_ROLE="{{ .node_role }}"
export NODE_IP="{{ .node_ip }}"
export CLUSTER_MEMBER="{{ .cluster_member }}"

{{/* Network configuration based on node role */}}
{{- if .is_gateway }}
# Gateway node network configuration
export IS_GATEWAY=true
export DNS_SERVER_ROLE=true
export NFS_SERVER_ROLE=true
export EXTERNAL_ACCESS=true

# Gateway-specific aliases
alias check-dns='dig @localhost example.com'
alias pihole-status='systemctl status pihole-FTL'
alias nfs-exports='showmount -e'
alias caddy-reload='sudo systemctl reload caddy'

{{- else }}
# Non-gateway node configuration
export IS_GATEWAY=false
export DNS_SERVER="{{ .dns_server }}"
export NFS_SERVER="{{ .nfs_server }}"
export GATEWAY="{{ .gateway_ip }}"

# Non-gateway aliases
alias connect-gateway='ssh {{ .gateway_ip }}'
alias check-internet='ping -c 3 8.8.8.8'
{{- end }}

{{/* GPU configuration section */}}
{{- if .has_gpu }}
# GPU configuration for {{ .gpu_architecture }} setup
export HAS_GPU=true
export GPU_COUNT={{ .gpu_count }}
export GPU_ARCHITECTURE="{{ .gpu_architecture }}"

{{- if .has_cuda_toolkit }}
# CUDA development environment
export CUDA_HOME="{{ .cuda_home }}"
export CUDA_VERSION="{{ .cuda_version }}"
export PATH="$CUDA_HOME/bin:$PATH"
export LD_LIBRARY_PATH="$CUDA_HOME/lib64:$LD_LIBRARY_PATH"
export CUDA_INCLUDE_PATH="$CUDA_HOME/include"

# CUDA development aliases
alias cuda-version='nvcc --version'
alias cuda-devices='nvidia-smi -L'
alias cuda-compile='nvcc -O3 -arch=sm_61'
{{- end }}

# GPU monitoring aliases
alias gpus='nvidia-smi'
alias gpu-watch='watch -n 1 nvidia-smi'
alias gpu-mem='nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader'
alias gpu-util='nvidia-smi --query-gpu=utilization.gpu,utilization.memory --format=csv,noheader'
alias gpu-temp='nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader'
alias gpu-power='nvidia-smi --query-gpu=power.draw,power.limit --format=csv,noheader'

{{- if eq .gpu_architecture "multi_gpu" }}
# Multi-GPU specific configuration (projector)
export CUDA_DEVICE_ORDER="PCI_BUS_ID"
export NCCL_DEBUG=INFO
export OMP_NUM_THREADS=8

# Multi-GPU aliases
alias gpu-topology='nvidia-smi topo -m'
alias gpu-reset-all='sudo nvidia-smi -r'
alias distributed-test='python -m torch.distributed.launch --nproc_per_node={{ .gpu_count }}'

{{- else if eq .gpu_architecture "single_gpu" }}
# Single GPU optimization (director)
export CUDA_DEVICE_ORDER="FASTEST_FIRST"
export OMP_NUM_THREADS=4

# Single GPU development aliases
alias gpu-exclusive='sudo nvidia-smi -c 3'
alias gpu-default='sudo nvidia-smi -c 0'
{{- end }}

{{- else }}
# No GPU configuration
export HAS_GPU=false
export GPU_COUNT=0
{{- end }}

{{/* Docker and container configuration */}}
{{- if .has_docker }}
# Docker configuration
export DOCKER_BUILDKIT=1
export COMPOSE_DOCKER_CLI_BUILD=1

{{- if .has_nvidia_container }}
# Docker GPU runtime
export DOCKER_DEFAULT_RUNTIME=nvidia
export NVIDIA_VISIBLE_DEVICES=all
export NVIDIA_DRIVER_CAPABILITIES="compute,utility,graphics"

# Docker GPU aliases
alias docker-gpu='docker run --gpus all'
alias docker-gpu-it='docker run -it --rm --gpus all'
alias docker-gpu-test='docker run --rm --gpus all nvidia/cuda:{{ .cuda_version }}-base-ubuntu20.04 nvidia-smi'
{{- end }}

# Docker convenience aliases
alias dps='docker ps --format "table {{`{{.Names}}`}}\t{{`{{.Status}}`}}\t{{`{{.Ports}}`}}"'
alias dimg='docker images --format "table {{`{{.Repository}}`}}\t{{`{{.Tag}}`}}\t{{`{{.Size}}`}}"'
alias dlog='docker logs -f'
alias dexec='docker exec -it'
alias dclean='docker system prune -f'
{{- end }}

{{/* Service-specific configuration */}}
{{- if .has_archon_service }}
# Archon service management (projector)
export ARCHON_HOST="projector.ism.la"
export ARCHON_SERVICES="server,mcp,agents"

# Archon aliases
alias archon-status='systemctl status archon.service'
alias archon-logs='sudo journalctl -u archon.service -f'
alias archon-restart='sudo systemctl restart archon.service'
alias archon-containers='docker ps --filter "name=archon" --format "table {{`{{.Names}}`}}\t{{`{{.Status}}`}}"'

# Archon health checks
alias archon-health='curl -f http://localhost:8181/health && curl -f http://localhost:8051/health && curl -f http://localhost:8052/health'
alias archon-db='docker exec -it archon_postgres psql -U postgres'
{{- end }}

{{- if .has_ollama_service }}
# Ollama service management
export OLLAMA_HOST="0.0.0.0:11434"
export OLLAMA_MODELS="/var/lib/ollama/models"

# Ollama aliases
alias ollama-status='systemctl status ollama.service'
alias ollama-logs='sudo journalctl -u ollama.service -f'
alias ollama-restart='sudo systemctl restart ollama.service'
alias ollama-models='ollama list'
alias ollama-pull='ollama pull'
alias ollama-run='ollama run'

{{- if .has_gpu }}
# GPU-accelerated Ollama
alias ollama-gpu-info='curl http://localhost:11434/api/ps'
{{- end }}
{{- end }}

{{/* Development tools configuration */}}
{{- if .uses_uv }}
# UV Python package manager
export UV_EXTRA_INDEX_URL="{{ .python_gpu_package_index }}"
{{- if .has_cuda_toolkit }}
export UV_CUDA_VERSION="{{ .cuda_version }}"
{{- end }}

# UV aliases
alias uv-install='uv add'
alias uv-env='uv venv'
alias uv-run='uv run'
alias uv-sync='uv sync'
{{- end }}

{{/* Tool detection and conditional aliases */}}
{{- if .HAS_EZA }}
# Modern ls replacement
alias ls='eza'
alias ll='eza -la'
alias la='eza -la'
alias lt='eza --tree'
alias lg='eza -la --git'
{{- else }}
# Traditional ls with colors
alias ls='ls --color=auto'
alias ll='ls -alF'
alias la='ls -A'
alias l='ls -CF'
{{- end }}

{{- if .HAS_BAT }}
# Syntax-highlighted cat
alias cat='bat'
alias less='bat'
{{- end }}

{{- if .HAS_FZF }}
# Fuzzy finder integration
export FZF_DEFAULT_OPTS='--height 40% --layout=reverse --border'
alias preview='fzf --preview "bat --color=always {}"'
{{- end }}

{{- if .HAS_ZOXIDE }}
# Smart cd replacement
# Note: zoxide init is handled in shell-specific configs
alias j='z'  # Jump alias for zoxide
{{- end }}

{{/* Cluster management aliases */}}
{{- if .cluster_member }}
# Cluster management
alias cluster-ping='ansible all -m ping'
alias cluster-status='for node in crtr prtr drtr; do echo "=== $node ==="; ssh $node "uptime; free -h"; done'
alias cluster-update='chezmoi update'

# Node-specific SSH aliases
alias ssh-cooperator='ssh cooperator.ism.la'
alias ssh-projector='ssh projector.ism.la'
alias ssh-director='ssh director.ism.la'

# Cluster health check
cluster-health() {
    echo "=== Cluster Health Check ==="
    for node in cooperator projector director; do
        echo "--- $node ---"
        if ssh -o ConnectTimeout=5 $node.ism.la "echo 'OK'"; then
            echo "✅ $node: reachable"
        else
            echo "❌ $node: unreachable"
        fi
    done
}
{{- end }}

{{/* Service management based on capabilities */}}
{{- if .has_service_management }}
# Service management aliases
alias svc-status='systemctl status'
alias svc-start='sudo systemctl start'
alias svc-stop='sudo systemctl stop'
alias svc-restart='sudo systemctl restart'
alias svc-enable='sudo systemctl enable'
alias svc-disable='sudo systemctl disable'
alias svc-logs='sudo journalctl -u'
alias svc-follow='sudo journalctl -u -f'

# Service health overview
service-overview() {
    echo "=== Service Status Overview ==="
    {{- if .has_archon_service }}
    echo "Archon: $(systemctl is-active archon.service)"
    {{- end }}
    {{- if .has_ollama_service }}
    echo "Ollama: $(systemctl is-active ollama.service)"
    {{- end }}
    {{- if .has_docker }}
    echo "Docker: $(systemctl is-active docker.service)"
    {{- end }}
    {{- if .has_gpu }}
    echo "NVIDIA: $(systemctl is-active nvidia-persistenced.service)"
    {{- end }}
    echo "SSH: $(systemctl is-active ssh.service)"
    {{- if .is_gateway }}
    echo "Pi-hole: $(systemctl is-active pihole-FTL.service)"
    echo "NFS: $(systemctl is-active nfs-kernel-server.service)"
    {{- else }}
    echo "NFS Client: $(systemctl is-active nfs-client.target)"
    {{- end }}
}
{{- end }}

{{/* Repository and configuration management */}}
# Configuration management
alias config-status='chezmoi status'
alias config-diff='chezmoi diff'
alias config-apply='chezmoi apply'
alias config-update='chezmoi update'
alias config-data='chezmoi data'

# Repository navigation
{{- if .node_config_path }}
alias goto-node-config='cd {{ .node_config_path }}'
{{- end }}
alias goto-cluster-config='cd /cluster-nas/colab/colab-config'
alias goto-docs='cd /cluster-nas/colab/colab-config/docs'

{{/* Node-specific functions */}}
{{- if eq .node_role "gateway" }}
# Gateway-specific functions
check-cluster-dns() {
    echo "Testing DNS resolution for cluster nodes:"
    for node in cooperator projector director; do
        if dig +short $node.ism.la > /dev/null; then
            echo "✅ $node.ism.la resolves"
        else
            echo "❌ $node.ism.la fails"
        fi
    done
}

nfs-client-status() {
    echo "NFS client connections:"
    showmount -a
}

{{- else if eq .node_role "compute" }}
# Compute node specific functions
gpu-benchmark() {
    echo "Running GPU benchmark..."
    {{- if .has_cuda_toolkit }}
    if command -v gpu-burn >/dev/null; then
        gpu-burn 60
    else
        echo "gpu-burn not installed, running basic test"
        nvidia-smi
    fi
    {{- else }}
    nvidia-smi
    {{- end }}
}

archon-full-restart() {
    echo "Performing full Archon restart..."
    sudo systemctl stop archon.service
    docker stop $(docker ps --filter "name=archon" -q)
    sleep 5
    docker start $(docker ps -a --filter "name=archon" -q)
    sleep 10
    sudo systemctl start archon.service
    echo "Archon restart complete"
}

{{- else if eq .node_role "ml_platform" }}
# ML platform specific functions
jupyter-tunnel() {
    local port=${1:-8888}
    echo "Creating Jupyter tunnel on port $port"
    ssh -N -L $port:localhost:$port director.ism.la
}

model-status() {
    echo "=== Ollama Models ==="
    ollama list
    echo ""
    echo "=== GPU Memory Usage ==="
    nvidia-smi --query-gpu=memory.used,memory.total --format=csv
}

python-env-info() {
    echo "=== Python Environment ==="
    echo "Python: $(python3 --version)"
    echo "Pip: $(pip3 --version)"
    {{- if .uses_uv }}
    echo "UV: $(uv --version)"
    {{- end }}
    echo ""
    echo "=== GPU Libraries ==="
    python3 -c "
import sys
try:
    import torch
    print(f'PyTorch: {torch.__version__}')
    print(f'CUDA available: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'GPU: {torch.cuda.get_device_name(0)}')
except ImportError:
    print('PyTorch: Not installed')

try:
    import tensorflow as tf
    print(f'TensorFlow: {tf.__version__}')
    print(f'GPU devices: {len(tf.config.list_physical_devices(\"GPU\"))}')
except ImportError:
    print('TensorFlow: Not installed')
"
}
{{- end }}

{{/* Performance monitoring functions */}}
{{- if .has_gpu }}
gpu-monitor() {
    local interval=${1:-1}
    echo "Monitoring GPU usage (update every ${interval}s, Ctrl+C to stop)"
    watch -n $interval "nvidia-smi --query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total,temperature.gpu,power.draw --format=csv"
}

gpu-processes() {
    echo "=== GPU Processes ==="
    nvidia-smi pmon -i 0 -c 1
}
{{- end }}

# System monitoring
system-overview() {
    echo "=== System Overview for {{ .chezmoi.hostname }} ==="
    echo "Node Role: {{ .node_role }}"
    echo "Uptime: $(uptime -p)"
    echo "Load: $(uptime | awk -F'load average:' '{print $2}')"
    echo "Memory: $(free -h | grep '^Mem' | awk '{print $3"/"$2" ("$5" available)"}')"
    echo "Disk: $(df -h / | tail -1 | awk '{print $3"/"$2" ("$5" used)"}')"
    {{- if .has_gpu }}
    echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)"
    {{- end }}
    echo ""
    service-overview
}

# Welcome message and node information
welcome-message() {
    echo "🚀 Welcome to {{ .chezmoi.hostname }} ({{ .node_role }})"
    {{- if .has_gpu }}
    echo "⚡ GPU: {{ .gpu_count }} device(s) available"
    {{- end }}
    {{- if .is_gateway }}
    echo "🌐 Gateway services: DNS, NFS, Proxy"
    {{- end }}
    {{- if .has_archon_service }}
    echo "🤖 Archon platform ready"
    {{- end }}
    {{- if .has_ollama_service }}
    echo "🧠 Ollama LLM service available"
    {{- end }}
    echo "📋 Type 'system-overview' for detailed status"
}

# Auto-run welcome message in interactive shells
if [[ $- == *i* ]]; then
    welcome-message
fi

{{/* Template debugging helpers */}}
# Template debugging (only available in development)
template-debug() {
    echo "=== Chezmoi Template Debug Info ==="
    echo "Hostname: {{ .chezmoi.hostname }}"
    echo "Architecture: {{ .chezmoi.arch }}"
    echo "Node Role: {{ .node_role }}"
    echo "Has GPU: {{ .has_gpu }}"
    {{- if .has_gpu }}
    echo "GPU Count: {{ .gpu_count }}"
    echo "GPU Architecture: {{ .gpu_architecture }}"
    {{- end }}
    echo "Has Docker: {{ .has_docker }}"
    echo "Cluster Member: {{ .cluster_member }}"
    echo ""
    echo "=== Tool Detection ==="
    {{- range $tool, $available := dict "EZA" .HAS_EZA "BAT" .HAS_BAT "FZF" .HAS_FZF "ZOXIDE" .HAS_ZOXIDE }}
    echo "{{ $tool }}: {{ if $available }}✅ Available{{ else }}❌ Not found{{ end }}"
    {{- end }}
}

# Configuration validation
validate-config() {
    echo "=== Configuration Validation ==="

    # Check required environment variables
    local required_vars=("CLUSTER_NODE" "NODE_ROLE" "NODE_IP")
    for var in "${required_vars[@]}"; do
        if [[ -n "${!var}" ]]; then
            echo "✅ $var: ${!var}"
        else
            echo "❌ $var: Not set"
        fi
    done

    # Check critical services
    {{- if .has_gpu }}
    if nvidia-smi >/dev/null 2>&1; then
        echo "✅ GPU: Accessible"
    else
        echo "❌ GPU: Not accessible"
    fi
    {{- end }}

    {{- if .has_docker }}
    if docker info >/dev/null 2>&1; then
        echo "✅ Docker: Running"
    else
        echo "❌ Docker: Not running"
    fi
    {{- end }}

    # Check network connectivity
    if ping -c 1 {{ .gateway_ip }} >/dev/null 2>&1; then
        echo "✅ Gateway: Reachable"
    else
        echo "❌ Gateway: Unreachable"
    fi

    # Check NFS mount
    if mountpoint -q /cluster-nas; then
        echo "✅ NFS: Mounted"
    else
        echo "❌ NFS: Not mounted"
    fi
}

{{/* Footer */}}
# Node-specific configuration loaded for {{ .chezmoi.hostname }}
# Configuration last updated: {{ now | date "2006-01-02 15:04:05" }}
# Template version: 1.0
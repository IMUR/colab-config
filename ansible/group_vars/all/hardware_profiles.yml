# Hardware profiles for cluster nodes
# Basic profiles that can be extended as needs grow

hardware_profiles:
  pi5_edge:
    arch: aarch64
    cpu_cores: 4
    memory_gb: 16
    ai_accelerator: hailo8
    ai_tops: 26
    storage:
      boot: "1tb_usb3"
      cluster: "2tb_nvme_usbc"
    network_role: gateway
    power_profile: low
    
  x86_multi_gpu:
    arch: x86_64
    cpu_model: "i9-9900x"
    cpu_cores: 10
    memory_gb: 128
    gpu:
      - {model: "gtx1080", count: 2, memory_gb: 8}
      - {model: "gtx970", count: 2, memory_gb: 4}
    storage:
      type: nvme
    network_role: compute
    power_profile: high
    
  x86_single_gpu:
    arch: x86_64
    cpu_model: "i9-9900k"
    cpu_cores: 8
    memory_gb: 64
    gpu:
      - {model: "rtx2080", count: 1, memory_gb: 8}
    storage:
      type: nvme
    network_role: worker
    power_profile: medium
    
  x86_basic:
    arch: x86_64
    cpu_model: "basic"
    memory_gb: 8
    gpu: []
    storage:
      type: sata
    network_role: client
    power_profile: low

# Service capabilities by hardware profile
service_capabilities:
  pi5_edge:
    can_run: [dns, proxy, edge_ai, monitoring, storage]
    optimal_for: [network_services, edge_inference]
    
  x86_multi_gpu:
    can_run: [containers, gpu_compute, ml_serving, storage]
    optimal_for: [burst_workloads, multi_model_inference]
    
  x86_single_gpu:
    can_run: [containers, gpu_compute, ml_training, background_jobs]
    optimal_for: [dedicated_training, long_running_tasks]
    
  x86_basic:
    can_run: [monitoring, ssh_access, basic_services]
    optimal_for: [mobile_access, monitoring]